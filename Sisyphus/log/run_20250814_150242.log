2025-08-14 15:02:42,760 INFO: Waiting for Ollama to be ready...
2025-08-14 15:02:44,797 INFO: Ollama is running.
2025-08-14 15:02:44,860 INFO: Refreshing options...
2025-08-14 15:02:46,913 INFO: Options refreshed:
2025-08-14 15:02:46,913 INFO: Models: ['deepseek-r1:8b', 'llama3:8b']
2025-08-14 15:02:46,913 INFO: Systems: ['system1.txt', 'system_consistency.txt', 'system_consistency_cl.txt', 'system_cover_letter.txt']
2025-08-14 15:02:46,913 INFO: CVs: ['cv1.txt']
2025-08-14 15:02:46,913 INFO: CV Templates: ['cv_template.docx', 'cv_template2.docx', 'cv_template21.docx', 'cv_template21_simplest.docx']
2025-08-14 15:02:46,913 INFO: CL Templates: ['cl_template.docx']
2025-08-14 15:02:46,913 INFO: Previously Saved CV Outputs: ['cltrials.txt', 'consistency_tests0.txt', 'out_cv_20250724_213613.txt', 'out_cv_20250725_000423.txt', 'out_cv_20250725_001236.txt', 'out_cv_20250725_003414.txt', 'out_cv_20250725_004330.txt', 'out_cv_20250725_005646.txt', 'out_cv_20250730_011841.txt', 'out_cv_20250730_020338.txt', 'stableish0.txt']
2025-08-14 15:02:46,913 INFO: Previously Saved CL Outputs: ['out_cl_20250722_234433.txt', 'out_cl_20250723_230452.txt']
2025-08-14 15:03:06,597 INFO: CV loaded from C:\CodeProjects\Sisyphus\Sisyphus\saved_outputs\consistency_tests0.txt
2025-08-14 15:03:24,612 INFO: Tailoring cover letter with model: llama3:8b
2025-08-14 15:03:25,043 INFO: JS Output: 97

2025-08-14 15:03:25,043 INFO: [MODEL: llama3:8b] Input token usage: 2.37%
2025-08-14 15:03:25,043 INFO: [MODEL: llama3:8b] Input uses 97 tokens, remaining for response: 3999.
2025-08-14 15:03:40,079 INFO: JS Output: 360

2025-08-14 15:03:40,079 INFO: [MODEL: llama3:8b] Output token usage: 8.79%
2025-08-14 15:03:40,079 INFO: [MODEL: llama3:8b] Output uses 360 tokens, remaining for response: 3639.
2025-08-14 15:03:40,087 INFO: slide_summary: candidate_name: Jane Doe
2025-08-14 15:03:40,087 INFO: slide_summary: candidate_title: Senior Software Engineer
2025-08-14 15:03:40,088 INFO: slide_summary: general_txts: 4
2025-08-14 15:03:40,088 INFO: slide_summary: special_txts: 6
2025-08-14 15:03:40,536 INFO: JS Output: 241

2025-08-14 15:03:40,536 INFO: [MODEL: llama3:8b] Input token usage: 5.88%
2025-08-14 15:03:40,536 INFO: [MODEL: llama3:8b] Input uses 241 tokens, remaining for response: 3855.
2025-08-14 15:03:56,780 INFO: JS Output: 105

2025-08-14 15:03:56,796 INFO: [MODEL: llama3:8b] Output token usage: 2.56%
2025-08-14 15:03:56,796 INFO: [MODEL: llama3:8b] Output uses 105 tokens, remaining for response: 3750.
2025-08-14 15:03:57,269 INFO: JS Output: 191

2025-08-14 15:03:57,269 INFO: [MODEL: llama3:8b] Input token usage: 4.66%
2025-08-14 15:03:57,269 INFO: [MODEL: llama3:8b] Input uses 191 tokens, remaining for response: 3905.
2025-08-14 15:04:14,109 INFO: JS Output: 94

2025-08-14 15:04:14,109 INFO: [MODEL: llama3:8b] Output token usage: 2.29%
2025-08-14 15:04:14,109 INFO: [MODEL: llama3:8b] Output uses 94 tokens, remaining for response: 3811.
2025-08-14 15:04:14,589 INFO: JS Output: 320

2025-08-14 15:04:14,589 INFO: [MODEL: llama3:8b] Input token usage: 7.81%
2025-08-14 15:04:14,589 INFO: [MODEL: llama3:8b] Input uses 320 tokens, remaining for response: 3776.
2025-08-14 15:04:36,184 INFO: JS Output: 165

2025-08-14 15:04:36,184 INFO: [MODEL: llama3:8b] Output token usage: 4.03%
2025-08-14 15:04:36,184 INFO: [MODEL: llama3:8b] Output uses 165 tokens, remaining for response: 3611.
2025-08-14 15:04:36,642 INFO: JS Output: 191

2025-08-14 15:04:36,642 INFO: [MODEL: llama3:8b] Input token usage: 4.66%
2025-08-14 15:04:36,642 INFO: [MODEL: llama3:8b] Input uses 191 tokens, remaining for response: 3905.
2025-08-14 15:04:42,173 INFO: JS Output: 82

2025-08-14 15:04:42,173 INFO: [MODEL: llama3:8b] Output token usage: 2.00%
2025-08-14 15:04:42,173 INFO: [MODEL: llama3:8b] Output uses 82 tokens, remaining for response: 3823.
2025-08-14 15:04:42,634 INFO: JS Output: 194

2025-08-14 15:04:42,634 INFO: [MODEL: llama3:8b] Input token usage: 4.74%
2025-08-14 15:04:42,634 INFO: [MODEL: llama3:8b] Input uses 194 tokens, remaining for response: 3902.
2025-08-14 15:04:49,145 INFO: JS Output: 110

2025-08-14 15:04:49,145 INFO: [MODEL: llama3:8b] Output token usage: 2.69%
2025-08-14 15:04:49,145 INFO: [MODEL: llama3:8b] Output uses 110 tokens, remaining for response: 3792.
2025-08-14 15:04:49,575 INFO: JS Output: 319

2025-08-14 15:04:49,575 INFO: [MODEL: llama3:8b] Input token usage: 7.79%
2025-08-14 15:04:49,575 INFO: [MODEL: llama3:8b] Input uses 319 tokens, remaining for response: 3777.
2025-08-14 15:04:58,948 INFO: JS Output: 185

2025-08-14 15:04:58,948 INFO: [MODEL: llama3:8b] Output token usage: 4.52%
2025-08-14 15:04:58,948 INFO: [MODEL: llama3:8b] Output uses 185 tokens, remaining for response: 3592.
2025-08-14 15:04:59,403 INFO: JS Output: 194

2025-08-14 15:04:59,403 INFO: [MODEL: llama3:8b] Input token usage: 4.74%
2025-08-14 15:04:59,403 INFO: [MODEL: llama3:8b] Input uses 194 tokens, remaining for response: 3902.
2025-08-14 15:05:05,883 INFO: JS Output: 108

2025-08-14 15:05:05,883 INFO: [MODEL: llama3:8b] Output token usage: 2.64%
2025-08-14 15:05:05,883 INFO: [MODEL: llama3:8b] Output uses 108 tokens, remaining for response: 3794.
2025-08-14 15:05:06,320 INFO: JS Output: 350

2025-08-14 15:05:06,320 INFO: [MODEL: llama3:8b] Input token usage: 8.54%
2025-08-14 15:05:06,320 INFO: [MODEL: llama3:8b] Input uses 350 tokens, remaining for response: 3746.
2025-08-14 15:05:13,561 INFO: JS Output: 124

2025-08-14 15:05:13,561 INFO: [MODEL: llama3:8b] Output token usage: 3.03%
2025-08-14 15:05:13,561 INFO: [MODEL: llama3:8b] Output uses 124 tokens, remaining for response: 3622.
2025-08-14 15:05:14,011 INFO: JS Output: 363

2025-08-14 15:05:14,011 INFO: [MODEL: llama3:8b] Input token usage: 8.86%
2025-08-14 15:05:14,011 INFO: [MODEL: llama3:8b] Input uses 363 tokens, remaining for response: 3733.
2025-08-14 15:05:24,229 INFO: JS Output: 208

2025-08-14 15:05:24,229 INFO: [MODEL: llama3:8b] Output token usage: 5.08%
2025-08-14 15:05:24,229 INFO: [MODEL: llama3:8b] Output uses 208 tokens, remaining for response: 3525.
2025-08-14 15:05:24,687 INFO: JS Output: 350

2025-08-14 15:05:24,687 INFO: [MODEL: llama3:8b] Input token usage: 8.54%
2025-08-14 15:05:24,687 INFO: [MODEL: llama3:8b] Input uses 350 tokens, remaining for response: 3746.
2025-08-14 15:05:31,175 INFO: JS Output: 101

2025-08-14 15:05:31,175 INFO: [MODEL: llama3:8b] Output token usage: 2.47%
2025-08-14 15:05:31,175 INFO: [MODEL: llama3:8b] Output uses 101 tokens, remaining for response: 3645.
2025-08-14 15:05:31,635 INFO: JS Output: 269

2025-08-14 15:05:31,637 INFO: [MODEL: llama3:8b] Input token usage: 6.57%
2025-08-14 15:05:31,637 INFO: [MODEL: llama3:8b] Input uses 269 tokens, remaining for response: 3827.
2025-08-14 15:05:39,512 INFO: JS Output: 145

2025-08-14 15:05:39,512 INFO: [MODEL: llama3:8b] Output token usage: 3.54%
2025-08-14 15:05:39,512 INFO: [MODEL: llama3:8b] Output uses 145 tokens, remaining for response: 3682.
2025-08-14 15:05:39,976 INFO: JS Output: 374

2025-08-14 15:05:39,976 INFO: [MODEL: llama3:8b] Input token usage: 9.13%
2025-08-14 15:05:39,976 INFO: [MODEL: llama3:8b] Input uses 374 tokens, remaining for response: 3722.
2025-08-14 15:05:51,248 INFO: JS Output: 236

2025-08-14 15:05:51,248 INFO: [MODEL: llama3:8b] Output token usage: 5.76%
2025-08-14 15:05:51,248 INFO: [MODEL: llama3:8b] Output uses 236 tokens, remaining for response: 3486.
2025-08-14 15:05:51,690 INFO: JS Output: 269

2025-08-14 15:05:51,690 INFO: [MODEL: llama3:8b] Input token usage: 6.57%
2025-08-14 15:05:51,690 INFO: [MODEL: llama3:8b] Input uses 269 tokens, remaining for response: 3827.
2025-08-14 15:05:57,001 INFO: JS Output: 71

2025-08-14 15:05:57,001 INFO: [MODEL: llama3:8b] Output token usage: 1.73%
2025-08-14 15:05:57,001 INFO: [MODEL: llama3:8b] Output uses 71 tokens, remaining for response: 3756.
2025-08-14 15:05:57,450 INFO: JS Output: 187

2025-08-14 15:05:57,450 INFO: [MODEL: llama3:8b] Input token usage: 4.57%
2025-08-14 15:05:57,450 INFO: [MODEL: llama3:8b] Input uses 187 tokens, remaining for response: 3909.
2025-08-14 15:06:03,508 INFO: JS Output: 96

2025-08-14 15:06:03,508 INFO: [MODEL: llama3:8b] Output token usage: 2.34%
2025-08-14 15:06:03,508 INFO: [MODEL: llama3:8b] Output uses 96 tokens, remaining for response: 3813.
2025-08-14 15:06:03,958 INFO: JS Output: 289

2025-08-14 15:06:03,960 INFO: [MODEL: llama3:8b] Input token usage: 7.06%
2025-08-14 15:06:03,960 INFO: [MODEL: llama3:8b] Input uses 289 tokens, remaining for response: 3807.
2025-08-14 15:06:12,234 INFO: JS Output: 153

2025-08-14 15:06:12,234 INFO: [MODEL: llama3:8b] Output token usage: 3.74%
2025-08-14 15:06:12,234 INFO: [MODEL: llama3:8b] Output uses 153 tokens, remaining for response: 3654.
2025-08-14 15:06:12,697 INFO: JS Output: 184

2025-08-14 15:06:12,697 INFO: [MODEL: llama3:8b] Input token usage: 4.49%
2025-08-14 15:06:12,697 INFO: [MODEL: llama3:8b] Input uses 184 tokens, remaining for response: 3912.
2025-08-14 15:06:17,961 INFO: JS Output: 72

2025-08-14 15:06:17,961 INFO: [MODEL: llama3:8b] Output token usage: 1.76%
2025-08-14 15:06:17,961 INFO: [MODEL: llama3:8b] Output uses 72 tokens, remaining for response: 3840.
2025-08-14 15:06:18,405 INFO: JS Output: 72

2025-08-14 15:06:18,405 INFO: [MODEL: llama3:8b] Input token usage: 1.76%
2025-08-14 15:06:18,405 INFO: [MODEL: llama3:8b] Input uses 72 tokens, remaining for response: 4024.
2025-08-14 15:06:23,896 INFO: JS Output: 82

2025-08-14 15:06:23,896 INFO: [MODEL: llama3:8b] Output token usage: 2.00%
2025-08-14 15:06:23,896 INFO: [MODEL: llama3:8b] Output uses 82 tokens, remaining for response: 3942.
2025-08-14 15:06:24,367 INFO: JS Output: 751

2025-08-14 15:06:24,367 INFO: [MODEL: llama3:8b] Input token usage: 18.33%
2025-08-14 15:06:24,367 INFO: [MODEL: llama3:8b] Input uses 751 tokens, remaining for response: 3345.
2025-08-14 15:06:38,150 INFO: JS Output: 285

2025-08-14 15:06:38,150 INFO: [MODEL: llama3:8b] Output token usage: 6.96%
2025-08-14 15:06:38,150 INFO: [MODEL: llama3:8b] Output uses 285 tokens, remaining for response: 3060.
2025-08-14 15:06:38,601 INFO: JS Output: 645

2025-08-14 15:06:38,601 INFO: [MODEL: llama3:8b] Input token usage: 15.75%
2025-08-14 15:06:38,601 INFO: [MODEL: llama3:8b] Input uses 645 tokens, remaining for response: 3451.
2025-08-14 15:06:53,328 INFO: JS Output: 301

2025-08-14 15:06:53,328 INFO: [MODEL: llama3:8b] Output token usage: 7.35%
2025-08-14 15:06:53,329 INFO: [MODEL: llama3:8b] Output uses 301 tokens, remaining for response: 3150.
2025-08-14 15:06:53,330 INFO: Cover letter text generated successfully.
2025-08-14 15:06:53,791 INFO: JS Output: 97

2025-08-14 15:06:53,792 INFO: [MODEL: llama3:8b] Input token usage: 2.37%
2025-08-14 15:06:53,792 INFO: [MODEL: llama3:8b] Input uses 97 tokens, remaining for response: 3999.
2025-08-14 15:07:08,360 INFO: JS Output: 326

2025-08-14 15:07:08,361 INFO: [MODEL: llama3:8b] Output token usage: 7.96%
2025-08-14 15:07:08,361 INFO: [MODEL: llama3:8b] Output uses 326 tokens, remaining for response: 3673.
2025-08-14 15:07:08,820 INFO: JS Output: 734

2025-08-14 15:07:08,821 INFO: [MODEL: llama3:8b] Input token usage: 17.92%
2025-08-14 15:07:08,821 INFO: [MODEL: llama3:8b] Input uses 734 tokens, remaining for response: 3362.
2025-08-14 15:07:17,124 INFO: JS Output: 133

2025-08-14 15:07:17,125 INFO: [MODEL: llama3:8b] Output token usage: 3.25%
2025-08-14 15:07:17,125 INFO: [MODEL: llama3:8b] Output uses 133 tokens, remaining for response: 3229.
2025-08-14 15:07:17,125 INFO: Consistency Checker: Cover Letter VS Original Resume:
2025-08-14 15:07:17,125 INFO: slide_summary: candidate_name: Jane Doe
2025-08-14 15:07:17,125 INFO: slide_summary: candidate_title: Senior Software Engineer
2025-08-14 15:07:17,126 INFO: slide_summary: general_txts: 4
2025-08-14 15:07:17,126 INFO: slide_summary: special_txts: 0

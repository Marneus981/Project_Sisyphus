2025-08-14 16:31:53,089 INFO: Waiting for Ollama to be ready...
2025-08-14 16:31:55,131 INFO: Ollama is running.
2025-08-14 16:31:55,409 INFO: Refreshing options...
2025-08-14 16:31:57,460 INFO: Options refreshed:
2025-08-14 16:31:57,460 INFO: Models: ['deepseek-r1:8b', 'llama3:8b']
2025-08-14 16:31:57,460 INFO: Systems: ['system1.txt', 'system_consistency.txt', 'system_consistency_cl.txt', 'system_cover_letter.txt']
2025-08-14 16:31:57,460 INFO: CVs: ['cv1.txt']
2025-08-14 16:31:57,460 INFO: CV Templates: ['cv_template.docx', 'cv_template2.docx', 'cv_template21.docx', 'cv_template21_simplest.docx']
2025-08-14 16:31:57,460 INFO: CL Templates: ['cl_template.docx']
2025-08-14 16:31:57,460 INFO: Previously Saved CV Outputs: ['cltrials.txt', 'consistency_tests0.txt', 'out_cv_20250724_213613.txt', 'out_cv_20250725_000423.txt', 'out_cv_20250725_001236.txt', 'out_cv_20250725_003414.txt', 'out_cv_20250725_004330.txt', 'out_cv_20250725_005646.txt', 'out_cv_20250730_011841.txt', 'out_cv_20250730_020338.txt', 'stableish0.txt']
2025-08-14 16:31:57,460 INFO: Previously Saved CL Outputs: ['out_cl_20250722_234433.txt', 'out_cl_20250723_230452.txt']
2025-08-14 16:32:13,819 INFO: CV loaded from C:\CodeProjects\Sisyphus\Sisyphus\saved_outputs\consistency_tests0.txt
2025-08-14 16:32:18,405 INFO: JS Output: 97

2025-08-14 16:32:18,405 INFO: [MODEL: llama3:8b] Input token usage: 2.37%
2025-08-14 16:32:18,405 INFO: [MODEL: llama3:8b] Input uses 97 tokens, remaining for response: 3999.
2025-08-14 16:32:37,196 INFO: JS Output: 219

2025-08-14 16:32:37,196 INFO: [MODEL: llama3:8b] Output token usage: 5.35%
2025-08-14 16:32:37,196 INFO: [MODEL: llama3:8b] Output uses 219 tokens, remaining for response: 3780.
2025-08-14 16:32:37,198 INFO: slide_summary: candidate_name: Jane Doe
2025-08-14 16:32:37,198 INFO: slide_summary: candidate_title: Senior Software Engineer
2025-08-14 16:32:37,198 INFO: slide_summary: general_txts: 4
2025-08-14 16:32:37,198 INFO: slide_summary: special_txts: 6
2025-08-14 16:32:37,699 INFO: JS Output: 241

2025-08-14 16:32:37,699 INFO: [MODEL: llama3:8b] Input token usage: 5.88%
2025-08-14 16:32:37,699 INFO: [MODEL: llama3:8b] Input uses 241 tokens, remaining for response: 3855.
2025-08-14 16:32:43,487 INFO: JS Output: 66

2025-08-14 16:32:43,490 INFO: [MODEL: llama3:8b] Output token usage: 1.61%
2025-08-14 16:32:43,490 INFO: [MODEL: llama3:8b] Output uses 66 tokens, remaining for response: 3789.
2025-08-14 16:32:43,953 INFO: JS Output: 191

2025-08-14 16:32:43,953 INFO: [MODEL: llama3:8b] Input token usage: 4.66%
2025-08-14 16:32:43,953 INFO: [MODEL: llama3:8b] Input uses 191 tokens, remaining for response: 3905.
2025-08-14 16:32:51,688 INFO: JS Output: 113

2025-08-14 16:32:51,688 INFO: [MODEL: llama3:8b] Output token usage: 2.76%
2025-08-14 16:32:51,688 INFO: [MODEL: llama3:8b] Output uses 113 tokens, remaining for response: 3792.
2025-08-14 16:32:52,153 INFO: JS Output: 300

2025-08-14 16:32:52,153 INFO: [MODEL: llama3:8b] Input token usage: 7.32%
2025-08-14 16:32:52,153 INFO: [MODEL: llama3:8b] Input uses 300 tokens, remaining for response: 3796.
2025-08-14 16:33:03,196 INFO: JS Output: 181

2025-08-14 16:33:03,196 INFO: [MODEL: llama3:8b] Output token usage: 4.42%
2025-08-14 16:33:03,196 INFO: [MODEL: llama3:8b] Output uses 181 tokens, remaining for response: 3615.
2025-08-14 16:33:03,662 INFO: JS Output: 191

2025-08-14 16:33:03,662 INFO: [MODEL: llama3:8b] Input token usage: 4.66%
2025-08-14 16:33:03,662 INFO: [MODEL: llama3:8b] Input uses 191 tokens, remaining for response: 3905.
2025-08-14 16:33:11,899 INFO: JS Output: 122

2025-08-14 16:33:11,899 INFO: [MODEL: llama3:8b] Output token usage: 2.98%
2025-08-14 16:33:11,899 INFO: [MODEL: llama3:8b] Output uses 122 tokens, remaining for response: 3783.
2025-08-14 16:33:12,378 INFO: JS Output: 194

2025-08-14 16:33:12,378 INFO: [MODEL: llama3:8b] Input token usage: 4.74%
2025-08-14 16:33:12,378 INFO: [MODEL: llama3:8b] Input uses 194 tokens, remaining for response: 3902.
2025-08-14 16:33:20,494 INFO: JS Output: 121

2025-08-14 16:33:20,494 INFO: [MODEL: llama3:8b] Output token usage: 2.95%
2025-08-14 16:33:20,494 INFO: [MODEL: llama3:8b] Output uses 121 tokens, remaining for response: 3781.
2025-08-14 16:33:20,963 INFO: JS Output: 370

2025-08-14 16:33:20,963 INFO: [MODEL: llama3:8b] Input token usage: 9.03%
2025-08-14 16:33:20,965 INFO: [MODEL: llama3:8b] Input uses 370 tokens, remaining for response: 3726.
2025-08-14 16:33:38,718 INFO: JS Output: 174

2025-08-14 16:33:38,718 INFO: [MODEL: llama3:8b] Output token usage: 4.25%
2025-08-14 16:33:38,718 INFO: [MODEL: llama3:8b] Output uses 174 tokens, remaining for response: 3552.
2025-08-14 16:33:39,193 INFO: JS Output: 194

2025-08-14 16:33:39,193 INFO: [MODEL: llama3:8b] Input token usage: 4.74%
2025-08-14 16:33:39,193 INFO: [MODEL: llama3:8b] Input uses 194 tokens, remaining for response: 3902.
2025-08-14 16:33:46,286 INFO: JS Output: 97

2025-08-14 16:33:46,286 INFO: [MODEL: llama3:8b] Output token usage: 2.37%
2025-08-14 16:33:46,286 INFO: [MODEL: llama3:8b] Output uses 97 tokens, remaining for response: 3805.
2025-08-14 16:33:46,749 INFO: JS Output: 350

2025-08-14 16:33:46,749 INFO: [MODEL: llama3:8b] Input token usage: 8.54%
2025-08-14 16:33:46,749 INFO: [MODEL: llama3:8b] Input uses 350 tokens, remaining for response: 3746.
2025-08-14 16:33:54,758 INFO: JS Output: 114

2025-08-14 16:33:54,758 INFO: [MODEL: llama3:8b] Output token usage: 2.78%
2025-08-14 16:33:54,758 INFO: [MODEL: llama3:8b] Output uses 114 tokens, remaining for response: 3632.
2025-08-14 16:33:55,229 INFO: JS Output: 342

2025-08-14 16:33:55,229 INFO: [MODEL: llama3:8b] Input token usage: 8.35%
2025-08-14 16:33:55,229 INFO: [MODEL: llama3:8b] Input uses 342 tokens, remaining for response: 3754.
2025-08-14 16:34:07,680 INFO: JS Output: 211

2025-08-14 16:34:07,680 INFO: [MODEL: llama3:8b] Output token usage: 5.15%
2025-08-14 16:34:07,680 INFO: [MODEL: llama3:8b] Output uses 211 tokens, remaining for response: 3543.
2025-08-14 16:34:08,155 INFO: JS Output: 350

2025-08-14 16:34:08,157 INFO: [MODEL: llama3:8b] Input token usage: 8.54%
2025-08-14 16:34:08,157 INFO: [MODEL: llama3:8b] Input uses 350 tokens, remaining for response: 3746.
2025-08-14 16:34:18,858 INFO: JS Output: 171

2025-08-14 16:34:18,862 INFO: [MODEL: llama3:8b] Output token usage: 4.17%
2025-08-14 16:34:18,862 INFO: [MODEL: llama3:8b] Output uses 171 tokens, remaining for response: 3575.
2025-08-14 16:34:19,343 INFO: JS Output: 269

2025-08-14 16:34:19,343 INFO: [MODEL: llama3:8b] Input token usage: 6.57%
2025-08-14 16:34:19,343 INFO: [MODEL: llama3:8b] Input uses 269 tokens, remaining for response: 3827.
2025-08-14 16:34:28,865 INFO: JS Output: 148

2025-08-14 16:34:28,865 INFO: [MODEL: llama3:8b] Output token usage: 3.61%
2025-08-14 16:34:28,865 INFO: [MODEL: llama3:8b] Output uses 148 tokens, remaining for response: 3679.
2025-08-14 16:34:29,341 INFO: JS Output: 447

2025-08-14 16:34:29,341 INFO: [MODEL: llama3:8b] Input token usage: 10.91%
2025-08-14 16:34:29,341 INFO: [MODEL: llama3:8b] Input uses 447 tokens, remaining for response: 3649.
2025-08-14 16:34:44,443 INFO: JS Output: 263

2025-08-14 16:34:44,443 INFO: [MODEL: llama3:8b] Output token usage: 6.42%
2025-08-14 16:34:44,443 INFO: [MODEL: llama3:8b] Output uses 263 tokens, remaining for response: 3386.
2025-08-14 16:34:44,923 INFO: JS Output: 269

2025-08-14 16:34:44,923 INFO: [MODEL: llama3:8b] Input token usage: 6.57%
2025-08-14 16:34:44,923 INFO: [MODEL: llama3:8b] Input uses 269 tokens, remaining for response: 3827.
2025-08-14 16:34:52,464 INFO: JS Output: 102

2025-08-14 16:34:52,464 INFO: [MODEL: llama3:8b] Output token usage: 2.49%
2025-08-14 16:34:52,464 INFO: [MODEL: llama3:8b] Output uses 102 tokens, remaining for response: 3725.
2025-08-14 16:34:52,944 INFO: JS Output: 187

2025-08-14 16:34:52,944 INFO: [MODEL: llama3:8b] Input token usage: 4.57%
2025-08-14 16:34:52,944 INFO: [MODEL: llama3:8b] Input uses 187 tokens, remaining for response: 3909.
2025-08-14 16:35:01,626 INFO: JS Output: 127

2025-08-14 16:35:01,626 INFO: [MODEL: llama3:8b] Output token usage: 3.10%
2025-08-14 16:35:01,626 INFO: [MODEL: llama3:8b] Output uses 127 tokens, remaining for response: 3782.
2025-08-14 16:35:02,129 INFO: JS Output: 351

2025-08-14 16:35:02,131 INFO: [MODEL: llama3:8b] Input token usage: 8.57%
2025-08-14 16:35:02,131 INFO: [MODEL: llama3:8b] Input uses 351 tokens, remaining for response: 3745.
2025-08-14 16:35:13,005 INFO: JS Output: 172

2025-08-14 16:35:13,005 INFO: [MODEL: llama3:8b] Output token usage: 4.20%
2025-08-14 16:35:13,005 INFO: [MODEL: llama3:8b] Output uses 172 tokens, remaining for response: 3573.
2025-08-14 16:35:13,478 INFO: JS Output: 184

2025-08-14 16:35:13,478 INFO: [MODEL: llama3:8b] Input token usage: 4.49%
2025-08-14 16:35:13,478 INFO: [MODEL: llama3:8b] Input uses 184 tokens, remaining for response: 3912.
2025-08-14 16:35:19,505 INFO: JS Output: 73

2025-08-14 16:35:19,505 INFO: [MODEL: llama3:8b] Output token usage: 1.78%
2025-08-14 16:35:19,505 INFO: [MODEL: llama3:8b] Output uses 73 tokens, remaining for response: 3839.
2025-08-14 16:35:19,976 INFO: JS Output: 72

2025-08-14 16:35:19,976 INFO: [MODEL: llama3:8b] Input token usage: 1.76%
2025-08-14 16:35:19,976 INFO: [MODEL: llama3:8b] Input uses 72 tokens, remaining for response: 4024.
2025-08-14 16:35:26,230 INFO: JS Output: 79

2025-08-14 16:35:26,230 INFO: [MODEL: llama3:8b] Output token usage: 1.93%
2025-08-14 16:35:26,230 INFO: [MODEL: llama3:8b] Output uses 79 tokens, remaining for response: 3945.
2025-08-14 16:35:26,703 INFO: JS Output: 729

2025-08-14 16:35:26,705 INFO: [MODEL: llama3:8b] Input token usage: 17.80%
2025-08-14 16:35:26,705 INFO: [MODEL: llama3:8b] Input uses 729 tokens, remaining for response: 3367.
2025-08-14 16:35:43,260 INFO: JS Output: 274

2025-08-14 16:35:43,260 INFO: [MODEL: llama3:8b] Output token usage: 6.69%
2025-08-14 16:35:43,260 INFO: [MODEL: llama3:8b] Output uses 274 tokens, remaining for response: 3093.
2025-08-14 16:35:43,751 INFO: JS Output: 749

2025-08-14 16:35:43,751 INFO: [MODEL: llama3:8b] Input token usage: 18.29%
2025-08-14 16:35:43,751 INFO: [MODEL: llama3:8b] Input uses 749 tokens, remaining for response: 3347.
2025-08-14 16:35:50,140 INFO: JS Output: 61

2025-08-14 16:35:50,144 INFO: [MODEL: llama3:8b] Output token usage: 1.49%
2025-08-14 16:35:50,144 INFO: [MODEL: llama3:8b] Output uses 61 tokens, remaining for response: 3286.
2025-08-14 16:35:50,145 INFO: Consistency Checker: Tailored Resume VS Original Resume:
2025-08-14 16:35:50,655 INFO: JS Output: 131

2025-08-14 16:35:50,659 INFO: [MODEL: llama3:8b] Input token usage: 3.20%
2025-08-14 16:35:50,659 INFO: [MODEL: llama3:8b] Input uses 131 tokens, remaining for response: 3965.
2025-08-14 16:36:00,401 INFO: JS Output: 149

2025-08-14 16:36:00,401 INFO: [MODEL: llama3:8b] Output token usage: 3.64%
2025-08-14 16:36:00,401 INFO: [MODEL: llama3:8b] Output uses 149 tokens, remaining for response: 3816.
2025-08-14 16:36:00,861 INFO: JS Output: 275

2025-08-14 16:36:00,861 INFO: [MODEL: llama3:8b] Input token usage: 6.71%
2025-08-14 16:36:00,861 INFO: [MODEL: llama3:8b] Input uses 275 tokens, remaining for response: 3821.
2025-08-14 16:36:09,633 INFO: JS Output: 123

2025-08-14 16:36:09,633 INFO: [MODEL: llama3:8b] Output token usage: 3.00%
2025-08-14 16:36:09,633 INFO: [MODEL: llama3:8b] Output uses 123 tokens, remaining for response: 3698.
2025-08-14 16:36:10,126 INFO: JS Output: 133

2025-08-14 16:36:10,126 INFO: [MODEL: llama3:8b] Input token usage: 3.25%
2025-08-14 16:36:10,126 INFO: [MODEL: llama3:8b] Input uses 133 tokens, remaining for response: 3963.
2025-08-14 16:36:24,862 INFO: JS Output: 256

2025-08-14 16:36:24,862 INFO: [MODEL: llama3:8b] Output token usage: 6.25%
2025-08-14 16:36:24,862 INFO: [MODEL: llama3:8b] Output uses 256 tokens, remaining for response: 3707.
2025-08-14 16:36:25,352 INFO: JS Output: 938

2025-08-14 16:36:25,363 INFO: [MODEL: llama3:8b] Input token usage: 22.90%
2025-08-14 16:36:25,363 INFO: [MODEL: llama3:8b] Input uses 938 tokens, remaining for response: 3158.
2025-08-14 16:36:39,905 INFO: JS Output: 226

2025-08-14 16:36:39,905 INFO: [MODEL: llama3:8b] Output token usage: 5.52%
2025-08-14 16:36:39,905 INFO: [MODEL: llama3:8b] Output uses 226 tokens, remaining for response: 2932.
2025-08-14 16:36:40,396 INFO: JS Output: 137

2025-08-14 16:36:40,396 INFO: [MODEL: llama3:8b] Input token usage: 3.34%
2025-08-14 16:36:40,396 INFO: [MODEL: llama3:8b] Input uses 137 tokens, remaining for response: 3959.
2025-08-14 16:36:55,907 INFO: JS Output: 140

2025-08-14 16:36:55,907 INFO: [MODEL: llama3:8b] Output token usage: 3.42%
2025-08-14 16:36:55,907 INFO: [MODEL: llama3:8b] Output uses 140 tokens, remaining for response: 3819.
2025-08-14 16:36:56,430 INFO: JS Output: 367

2025-08-14 16:36:56,430 INFO: [MODEL: llama3:8b] Input token usage: 8.96%
2025-08-14 16:36:56,430 INFO: [MODEL: llama3:8b] Input uses 367 tokens, remaining for response: 3729.
2025-08-14 16:37:06,410 INFO: JS Output: 151

2025-08-14 16:37:06,410 INFO: [MODEL: llama3:8b] Output token usage: 3.69%
2025-08-14 16:37:06,410 INFO: [MODEL: llama3:8b] Output uses 151 tokens, remaining for response: 3578.
2025-08-14 16:37:06,893 INFO: JS Output: 265

2025-08-14 16:37:06,893 INFO: [MODEL: llama3:8b] Input token usage: 6.47%
2025-08-14 16:37:06,893 INFO: [MODEL: llama3:8b] Input uses 265 tokens, remaining for response: 3831.
2025-08-14 16:37:16,411 INFO: JS Output: 136

2025-08-14 16:37:16,411 INFO: [MODEL: llama3:8b] Output token usage: 3.32%
2025-08-14 16:37:16,411 INFO: [MODEL: llama3:8b] Output uses 136 tokens, remaining for response: 3695.
2025-08-14 16:37:16,906 INFO: JS Output: 261

2025-08-14 16:37:16,907 INFO: [MODEL: llama3:8b] Input token usage: 6.37%
2025-08-14 16:37:16,907 INFO: [MODEL: llama3:8b] Input uses 261 tokens, remaining for response: 3835.
2025-08-14 16:37:27,613 INFO: JS Output: 171

2025-08-14 16:37:27,614 INFO: [MODEL: llama3:8b] Output token usage: 4.17%
2025-08-14 16:37:27,614 INFO: [MODEL: llama3:8b] Output uses 171 tokens, remaining for response: 3664.
2025-08-14 16:37:28,112 INFO: JS Output: 2290

2025-08-14 16:37:28,113 INFO: [MODEL: llama3:8b] Input token usage: 55.91%
2025-08-14 16:37:28,113 INFO: [MODEL: llama3:8b] Input uses 2290 tokens, remaining for response: 1806.
2025-08-14 16:37:48,064 INFO: JS Output: 262

2025-08-14 16:37:48,064 INFO: [MODEL: llama3:8b] Output token usage: 6.40%
2025-08-14 16:37:48,064 INFO: [MODEL: llama3:8b] Output uses 262 tokens, remaining for response: 1544.
2025-08-14 16:37:48,545 INFO: JS Output: 2065

2025-08-14 16:37:48,545 INFO: [MODEL: llama3:8b] Input token usage: 50.42%
2025-08-14 16:37:48,545 INFO: [MODEL: llama3:8b] Input uses 2065 tokens, remaining for response: 2031.
2025-08-14 16:38:17,054 INFO: JS Output: 280

2025-08-14 16:38:17,054 INFO: [MODEL: llama3:8b] Output token usage: 6.84%
2025-08-14 16:38:17,054 INFO: [MODEL: llama3:8b] Output uses 280 tokens, remaining for response: 1751.
2025-08-14 16:38:17,549 INFO: JS Output: 1700

2025-08-14 16:38:17,549 INFO: [MODEL: llama3:8b] Input token usage: 41.50%
2025-08-14 16:38:17,549 INFO: [MODEL: llama3:8b] Input uses 1700 tokens, remaining for response: 2396.
2025-08-14 16:38:32,431 INFO: JS Output: 202

2025-08-14 16:38:32,431 INFO: [MODEL: llama3:8b] Output token usage: 4.93%
2025-08-14 16:38:32,431 INFO: [MODEL: llama3:8b] Output uses 202 tokens, remaining for response: 2194.
2025-08-14 16:38:32,894 INFO: JS Output: 196

2025-08-14 16:38:32,894 INFO: [MODEL: llama3:8b] Input token usage: 4.79%
2025-08-14 16:38:32,894 INFO: [MODEL: llama3:8b] Input uses 196 tokens, remaining for response: 3900.
2025-08-14 16:38:48,368 INFO: JS Output: 260

2025-08-14 16:38:48,368 INFO: [MODEL: llama3:8b] Output token usage: 6.35%
2025-08-14 16:38:48,368 INFO: [MODEL: llama3:8b] Output uses 260 tokens, remaining for response: 3640.
2025-08-14 16:38:48,861 INFO: JS Output: 400

2025-08-14 16:38:48,861 INFO: [MODEL: llama3:8b] Input token usage: 9.77%
2025-08-14 16:38:48,861 INFO: [MODEL: llama3:8b] Input uses 400 tokens, remaining for response: 3696.
2025-08-14 16:38:58,061 INFO: JS Output: 129

2025-08-14 16:38:58,061 INFO: [MODEL: llama3:8b] Output token usage: 3.15%
2025-08-14 16:38:58,061 INFO: [MODEL: llama3:8b] Output uses 129 tokens, remaining for response: 3567.

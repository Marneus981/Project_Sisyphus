2025-08-14 15:12:50,421 INFO: Waiting for Ollama to be ready...
2025-08-14 15:12:52,432 INFO: Ollama is running.
2025-08-14 15:12:52,494 INFO: Refreshing options...
2025-08-14 15:12:54,561 INFO: Options refreshed:
2025-08-14 15:12:54,561 INFO: Models: ['deepseek-r1:8b', 'llama3:8b']
2025-08-14 15:12:54,561 INFO: Systems: ['system1.txt', 'system_consistency.txt', 'system_consistency_cl.txt', 'system_cover_letter.txt']
2025-08-14 15:12:54,561 INFO: CVs: ['cv1.txt']
2025-08-14 15:12:54,561 INFO: CV Templates: ['cv_template.docx', 'cv_template2.docx', 'cv_template21.docx', 'cv_template21_simplest.docx']
2025-08-14 15:12:54,561 INFO: CL Templates: ['cl_template.docx']
2025-08-14 15:12:54,561 INFO: Previously Saved CV Outputs: ['cltrials.txt', 'consistency_tests0.txt', 'out_cv_20250724_213613.txt', 'out_cv_20250725_000423.txt', 'out_cv_20250725_001236.txt', 'out_cv_20250725_003414.txt', 'out_cv_20250725_004330.txt', 'out_cv_20250725_005646.txt', 'out_cv_20250730_011841.txt', 'out_cv_20250730_020338.txt', 'stableish0.txt']
2025-08-14 15:12:54,561 INFO: Previously Saved CL Outputs: ['out_cl_20250722_234433.txt', 'out_cl_20250723_230452.txt']
2025-08-14 15:13:23,506 INFO: CV loaded from C:\CodeProjects\Sisyphus\Sisyphus\saved_outputs\consistency_tests0.txt
2025-08-14 15:13:28,167 INFO: Tailoring cover letter with model: llama3:8b
2025-08-14 15:13:28,601 INFO: JS Output: 97

2025-08-14 15:13:28,601 INFO: [MODEL: llama3:8b] Input token usage: 2.37%
2025-08-14 15:13:28,601 INFO: [MODEL: llama3:8b] Input uses 97 tokens, remaining for response: 3999.
2025-08-14 15:13:46,878 INFO: JS Output: 307

2025-08-14 15:13:46,878 INFO: [MODEL: llama3:8b] Output token usage: 7.50%
2025-08-14 15:13:46,878 INFO: [MODEL: llama3:8b] Output uses 307 tokens, remaining for response: 3692.
2025-08-14 15:13:46,882 INFO: slide_summary: candidate_name: Jane Doe
2025-08-14 15:13:46,882 INFO: slide_summary: candidate_title: Senior Software Engineer
2025-08-14 15:13:46,882 INFO: slide_summary: general_txts: 4
2025-08-14 15:13:46,882 INFO: slide_summary: special_txts: 6
2025-08-14 15:13:47,390 INFO: JS Output: 241

2025-08-14 15:13:47,390 INFO: [MODEL: llama3:8b] Input token usage: 5.88%
2025-08-14 15:13:47,390 INFO: [MODEL: llama3:8b] Input uses 241 tokens, remaining for response: 3855.
2025-08-14 15:13:56,004 INFO: JS Output: 134

2025-08-14 15:13:56,004 INFO: [MODEL: llama3:8b] Output token usage: 3.27%
2025-08-14 15:13:56,020 INFO: [MODEL: llama3:8b] Output uses 134 tokens, remaining for response: 3721.
2025-08-14 15:13:56,465 INFO: JS Output: 191

2025-08-14 15:13:56,465 INFO: [MODEL: llama3:8b] Input token usage: 4.66%
2025-08-14 15:13:56,465 INFO: [MODEL: llama3:8b] Input uses 191 tokens, remaining for response: 3905.
2025-08-14 15:14:04,214 INFO: JS Output: 115

2025-08-14 15:14:04,214 INFO: [MODEL: llama3:8b] Output token usage: 2.81%
2025-08-14 15:14:04,214 INFO: [MODEL: llama3:8b] Output uses 115 tokens, remaining for response: 3790.
2025-08-14 15:14:04,674 INFO: JS Output: 370

2025-08-14 15:14:04,674 INFO: [MODEL: llama3:8b] Input token usage: 9.03%
2025-08-14 15:14:04,674 INFO: [MODEL: llama3:8b] Input uses 370 tokens, remaining for response: 3726.
2025-08-14 15:14:16,576 INFO: JS Output: 202

2025-08-14 15:14:16,576 INFO: [MODEL: llama3:8b] Output token usage: 4.93%
2025-08-14 15:14:16,576 INFO: [MODEL: llama3:8b] Output uses 202 tokens, remaining for response: 3524.
2025-08-14 15:14:17,026 INFO: JS Output: 191

2025-08-14 15:14:17,026 INFO: [MODEL: llama3:8b] Input token usage: 4.66%
2025-08-14 15:14:17,026 INFO: [MODEL: llama3:8b] Input uses 191 tokens, remaining for response: 3905.
2025-08-14 15:14:23,915 INFO: JS Output: 96

2025-08-14 15:14:23,915 INFO: [MODEL: llama3:8b] Output token usage: 2.34%
2025-08-14 15:14:23,915 INFO: [MODEL: llama3:8b] Output uses 96 tokens, remaining for response: 3809.
2025-08-14 15:14:24,380 INFO: JS Output: 194

2025-08-14 15:14:24,380 INFO: [MODEL: llama3:8b] Input token usage: 4.74%
2025-08-14 15:14:24,380 INFO: [MODEL: llama3:8b] Input uses 194 tokens, remaining for response: 3902.
2025-08-14 15:14:31,203 INFO: JS Output: 94

2025-08-14 15:14:31,203 INFO: [MODEL: llama3:8b] Output token usage: 2.29%
2025-08-14 15:14:31,203 INFO: [MODEL: llama3:8b] Output uses 94 tokens, remaining for response: 3808.
2025-08-14 15:14:31,652 INFO: JS Output: 317

2025-08-14 15:14:31,652 INFO: [MODEL: llama3:8b] Input token usage: 7.74%
2025-08-14 15:14:31,652 INFO: [MODEL: llama3:8b] Input uses 317 tokens, remaining for response: 3779.
2025-08-14 15:14:43,255 INFO: JS Output: 194

2025-08-14 15:14:43,255 INFO: [MODEL: llama3:8b] Output token usage: 4.74%
2025-08-14 15:14:43,255 INFO: [MODEL: llama3:8b] Output uses 194 tokens, remaining for response: 3585.
2025-08-14 15:14:43,706 INFO: JS Output: 194

2025-08-14 15:14:43,706 INFO: [MODEL: llama3:8b] Input token usage: 4.74%
2025-08-14 15:14:43,706 INFO: [MODEL: llama3:8b] Input uses 194 tokens, remaining for response: 3902.
2025-08-14 15:14:50,956 INFO: JS Output: 102

2025-08-14 15:14:50,956 INFO: [MODEL: llama3:8b] Output token usage: 2.49%
2025-08-14 15:14:50,956 INFO: [MODEL: llama3:8b] Output uses 102 tokens, remaining for response: 3800.
2025-08-14 15:14:51,394 INFO: JS Output: 350

2025-08-14 15:14:51,394 INFO: [MODEL: llama3:8b] Input token usage: 8.54%
2025-08-14 15:14:51,394 INFO: [MODEL: llama3:8b] Input uses 350 tokens, remaining for response: 3746.
2025-08-14 15:14:59,914 INFO: JS Output: 126

2025-08-14 15:14:59,914 INFO: [MODEL: llama3:8b] Output token usage: 3.08%
2025-08-14 15:14:59,914 INFO: [MODEL: llama3:8b] Output uses 126 tokens, remaining for response: 3620.
2025-08-14 15:15:00,347 INFO: JS Output: 359

2025-08-14 15:15:00,347 INFO: [MODEL: llama3:8b] Input token usage: 8.76%
2025-08-14 15:15:00,347 INFO: [MODEL: llama3:8b] Input uses 359 tokens, remaining for response: 3737.
2025-08-14 15:15:12,600 INFO: JS Output: 206

2025-08-14 15:15:12,600 INFO: [MODEL: llama3:8b] Output token usage: 5.03%
2025-08-14 15:15:12,600 INFO: [MODEL: llama3:8b] Output uses 206 tokens, remaining for response: 3531.
2025-08-14 15:15:13,063 INFO: JS Output: 350

2025-08-14 15:15:13,063 INFO: [MODEL: llama3:8b] Input token usage: 8.54%
2025-08-14 15:15:13,063 INFO: [MODEL: llama3:8b] Input uses 350 tokens, remaining for response: 3746.
2025-08-14 15:15:23,389 INFO: JS Output: 163

2025-08-14 15:15:23,389 INFO: [MODEL: llama3:8b] Output token usage: 3.98%
2025-08-14 15:15:23,389 INFO: [MODEL: llama3:8b] Output uses 163 tokens, remaining for response: 3583.
2025-08-14 15:15:23,862 INFO: JS Output: 269

2025-08-14 15:15:23,862 INFO: [MODEL: llama3:8b] Input token usage: 6.57%
2025-08-14 15:15:23,862 INFO: [MODEL: llama3:8b] Input uses 269 tokens, remaining for response: 3827.
2025-08-14 15:15:31,525 INFO: JS Output: 104

2025-08-14 15:15:31,525 INFO: [MODEL: llama3:8b] Output token usage: 2.54%
2025-08-14 15:15:31,525 INFO: [MODEL: llama3:8b] Output uses 104 tokens, remaining for response: 3723.
2025-08-14 15:15:32,002 INFO: JS Output: 395

2025-08-14 15:15:32,002 INFO: [MODEL: llama3:8b] Input token usage: 9.64%
2025-08-14 15:15:32,002 INFO: [MODEL: llama3:8b] Input uses 395 tokens, remaining for response: 3701.
2025-08-14 15:15:46,766 INFO: JS Output: 259

2025-08-14 15:15:46,766 INFO: [MODEL: llama3:8b] Output token usage: 6.32%
2025-08-14 15:15:46,766 INFO: [MODEL: llama3:8b] Output uses 259 tokens, remaining for response: 3442.
2025-08-14 15:15:47,237 INFO: JS Output: 269

2025-08-14 15:15:47,237 INFO: [MODEL: llama3:8b] Input token usage: 6.57%
2025-08-14 15:15:47,237 INFO: [MODEL: llama3:8b] Input uses 269 tokens, remaining for response: 3827.
2025-08-14 15:15:56,051 INFO: JS Output: 132

2025-08-14 15:15:56,052 INFO: [MODEL: llama3:8b] Output token usage: 3.22%
2025-08-14 15:15:56,052 INFO: [MODEL: llama3:8b] Output uses 132 tokens, remaining for response: 3695.
2025-08-14 15:15:56,510 INFO: JS Output: 187

2025-08-14 15:15:56,510 INFO: [MODEL: llama3:8b] Input token usage: 4.57%
2025-08-14 15:15:56,510 INFO: [MODEL: llama3:8b] Input uses 187 tokens, remaining for response: 3909.
2025-08-14 15:16:03,504 INFO: JS Output: 97

2025-08-14 15:16:03,504 INFO: [MODEL: llama3:8b] Output token usage: 2.37%
2025-08-14 15:16:03,505 INFO: [MODEL: llama3:8b] Output uses 97 tokens, remaining for response: 3812.
2025-08-14 15:16:03,971 INFO: JS Output: 351

2025-08-14 15:16:03,971 INFO: [MODEL: llama3:8b] Input token usage: 8.57%
2025-08-14 15:16:03,972 INFO: [MODEL: llama3:8b] Input uses 351 tokens, remaining for response: 3745.
2025-08-14 15:16:15,346 INFO: JS Output: 186

2025-08-14 15:16:15,347 INFO: [MODEL: llama3:8b] Output token usage: 4.54%
2025-08-14 15:16:15,347 INFO: [MODEL: llama3:8b] Output uses 186 tokens, remaining for response: 3559.
2025-08-14 15:16:15,796 INFO: JS Output: 184

2025-08-14 15:16:15,796 INFO: [MODEL: llama3:8b] Input token usage: 4.49%
2025-08-14 15:16:15,797 INFO: [MODEL: llama3:8b] Input uses 184 tokens, remaining for response: 3912.
2025-08-14 15:16:21,707 INFO: JS Output: 66

2025-08-14 15:16:21,707 INFO: [MODEL: llama3:8b] Output token usage: 1.61%
2025-08-14 15:16:21,708 INFO: [MODEL: llama3:8b] Output uses 66 tokens, remaining for response: 3846.
2025-08-14 15:16:22,165 INFO: JS Output: 72

2025-08-14 15:16:22,166 INFO: [MODEL: llama3:8b] Input token usage: 1.76%
2025-08-14 15:16:22,166 INFO: [MODEL: llama3:8b] Input uses 72 tokens, remaining for response: 4024.
2025-08-14 15:16:26,464 INFO: JS Output: 39

2025-08-14 15:16:26,464 INFO: [MODEL: llama3:8b] Output token usage: 0.95%
2025-08-14 15:16:26,464 INFO: [MODEL: llama3:8b] Output uses 39 tokens, remaining for response: 3985.
2025-08-14 15:16:26,929 INFO: JS Output: 938

2025-08-14 15:16:26,929 INFO: [MODEL: llama3:8b] Input token usage: 22.90%
2025-08-14 15:16:26,931 INFO: [MODEL: llama3:8b] Input uses 938 tokens, remaining for response: 3158.
2025-08-14 15:16:52,566 INFO: JS Output: 459

2025-08-14 15:16:52,566 INFO: [MODEL: llama3:8b] Output token usage: 11.21%
2025-08-14 15:16:52,566 INFO: [MODEL: llama3:8b] Output uses 459 tokens, remaining for response: 2699.
2025-08-14 15:16:53,032 INFO: JS Output: 708

2025-08-14 15:16:53,032 INFO: [MODEL: llama3:8b] Input token usage: 17.29%
2025-08-14 15:16:53,032 INFO: [MODEL: llama3:8b] Input uses 708 tokens, remaining for response: 3388.
2025-08-14 15:17:12,749 INFO: JS Output: 334

2025-08-14 15:17:12,749 INFO: [MODEL: llama3:8b] Output token usage: 8.15%
2025-08-14 15:17:12,749 INFO: [MODEL: llama3:8b] Output uses 334 tokens, remaining for response: 3054.
2025-08-14 15:17:12,762 INFO: Cover letter text generated successfully.
2025-08-14 15:17:13,218 INFO: JS Output: 97

2025-08-14 15:17:13,218 INFO: [MODEL: llama3:8b] Input token usage: 2.37%
2025-08-14 15:17:13,218 INFO: [MODEL: llama3:8b] Input uses 97 tokens, remaining for response: 3999.
2025-08-14 15:17:30,032 INFO: JS Output: 304

2025-08-14 15:17:30,032 INFO: [MODEL: llama3:8b] Output token usage: 7.42%
2025-08-14 15:17:30,032 INFO: [MODEL: llama3:8b] Output uses 304 tokens, remaining for response: 3695.
2025-08-14 15:17:30,514 INFO: JS Output: 981

2025-08-14 15:17:30,514 INFO: [MODEL: llama3:8b] Input token usage: 23.95%
2025-08-14 15:17:30,514 INFO: [MODEL: llama3:8b] Input uses 981 tokens, remaining for response: 3115.
2025-08-14 15:17:40,665 INFO: JS Output: 128

2025-08-14 15:17:40,665 INFO: [MODEL: llama3:8b] Output token usage: 3.12%
2025-08-14 15:17:40,665 INFO: [MODEL: llama3:8b] Output uses 128 tokens, remaining for response: 2987.
2025-08-14 15:17:40,680 INFO: Consistency Checker: Cover Letter VS Original Resume:
2025-08-14 15:17:40,681 INFO: slide_summary: candidate_name: Jane Doe
2025-08-14 15:17:40,681 INFO: slide_summary: candidate_title: Senior Software Engineer
2025-08-14 15:17:40,681 INFO: slide_summary: general_txts: 4
2025-08-14 15:17:40,681 INFO: slide_summary: special_txts: 6
2025-08-14 15:17:41,184 INFO: JS Output: 241

2025-08-14 15:17:41,184 INFO: [MODEL: llama3:8b] Input token usage: 5.88%
2025-08-14 15:17:41,184 INFO: [MODEL: llama3:8b] Input uses 241 tokens, remaining for response: 3855.
2025-08-14 15:17:49,268 INFO: JS Output: 107

2025-08-14 15:17:49,268 INFO: [MODEL: llama3:8b] Output token usage: 2.61%
2025-08-14 15:17:49,268 INFO: [MODEL: llama3:8b] Output uses 107 tokens, remaining for response: 3748.
2025-08-14 15:17:49,781 INFO: JS Output: 191

2025-08-14 15:17:49,781 INFO: [MODEL: llama3:8b] Input token usage: 4.66%
2025-08-14 15:17:49,781 INFO: [MODEL: llama3:8b] Input uses 191 tokens, remaining for response: 3905.
2025-08-14 15:17:57,151 INFO: JS Output: 99

2025-08-14 15:17:57,151 INFO: [MODEL: llama3:8b] Output token usage: 2.42%
2025-08-14 15:17:57,151 INFO: [MODEL: llama3:8b] Output uses 99 tokens, remaining for response: 3806.
2025-08-14 15:17:57,670 INFO: JS Output: 327

2025-08-14 15:17:57,670 INFO: [MODEL: llama3:8b] Input token usage: 7.98%
2025-08-14 15:17:57,670 INFO: [MODEL: llama3:8b] Input uses 327 tokens, remaining for response: 3769.
2025-08-14 15:18:10,472 INFO: JS Output: 196

2025-08-14 15:18:10,472 INFO: [MODEL: llama3:8b] Output token usage: 4.79%
2025-08-14 15:18:10,472 INFO: [MODEL: llama3:8b] Output uses 196 tokens, remaining for response: 3573.
2025-08-14 15:18:11,001 INFO: JS Output: 191

2025-08-14 15:18:11,001 INFO: [MODEL: llama3:8b] Input token usage: 4.66%
2025-08-14 15:18:11,001 INFO: [MODEL: llama3:8b] Input uses 191 tokens, remaining for response: 3905.
2025-08-14 15:18:16,770 INFO: JS Output: 63

2025-08-14 15:18:16,770 INFO: [MODEL: llama3:8b] Output token usage: 1.54%
2025-08-14 15:18:16,772 INFO: [MODEL: llama3:8b] Output uses 63 tokens, remaining for response: 3842.
2025-08-14 15:18:17,364 INFO: JS Output: 194

2025-08-14 15:18:17,364 INFO: [MODEL: llama3:8b] Input token usage: 4.74%
2025-08-14 15:18:17,364 INFO: [MODEL: llama3:8b] Input uses 194 tokens, remaining for response: 3902.
2025-08-14 15:18:25,213 INFO: JS Output: 107

2025-08-14 15:18:25,213 INFO: [MODEL: llama3:8b] Output token usage: 2.61%
2025-08-14 15:18:25,213 INFO: [MODEL: llama3:8b] Output uses 107 tokens, remaining for response: 3795.
2025-08-14 15:18:25,796 INFO: JS Output: 297

2025-08-14 15:18:25,796 INFO: [MODEL: llama3:8b] Input token usage: 7.25%
2025-08-14 15:18:25,796 INFO: [MODEL: llama3:8b] Input uses 297 tokens, remaining for response: 3799.
2025-08-14 15:18:44,192 INFO: JS Output: 183

2025-08-14 15:18:44,192 INFO: [MODEL: llama3:8b] Output token usage: 4.47%
2025-08-14 15:18:44,192 INFO: [MODEL: llama3:8b] Output uses 183 tokens, remaining for response: 3616.
2025-08-14 15:18:44,756 INFO: JS Output: 194

2025-08-14 15:18:44,756 INFO: [MODEL: llama3:8b] Input token usage: 4.74%
2025-08-14 15:18:44,756 INFO: [MODEL: llama3:8b] Input uses 194 tokens, remaining for response: 3902.
2025-08-14 15:18:52,799 INFO: JS Output: 111

2025-08-14 15:18:52,799 INFO: [MODEL: llama3:8b] Output token usage: 2.71%
2025-08-14 15:18:52,799 INFO: [MODEL: llama3:8b] Output uses 111 tokens, remaining for response: 3791.
2025-08-14 15:18:53,348 INFO: JS Output: 350

2025-08-14 15:18:53,348 INFO: [MODEL: llama3:8b] Input token usage: 8.54%
2025-08-14 15:18:53,348 INFO: [MODEL: llama3:8b] Input uses 350 tokens, remaining for response: 3746.
2025-08-14 15:19:03,381 INFO: JS Output: 146

2025-08-14 15:19:03,381 INFO: [MODEL: llama3:8b] Output token usage: 3.56%
2025-08-14 15:19:03,383 INFO: [MODEL: llama3:8b] Output uses 146 tokens, remaining for response: 3600.
2025-08-14 15:19:03,920 INFO: JS Output: 388

2025-08-14 15:19:03,920 INFO: [MODEL: llama3:8b] Input token usage: 9.47%
2025-08-14 15:19:03,920 INFO: [MODEL: llama3:8b] Input uses 388 tokens, remaining for response: 3708.
2025-08-14 15:19:19,744 INFO: JS Output: 264

2025-08-14 15:19:19,744 INFO: [MODEL: llama3:8b] Output token usage: 6.45%
2025-08-14 15:19:19,744 INFO: [MODEL: llama3:8b] Output uses 264 tokens, remaining for response: 3444.
2025-08-14 15:19:20,234 INFO: JS Output: 350

2025-08-14 15:19:20,234 INFO: [MODEL: llama3:8b] Input token usage: 8.54%
2025-08-14 15:19:20,234 INFO: [MODEL: llama3:8b] Input uses 350 tokens, remaining for response: 3746.
2025-08-14 15:19:28,437 INFO: JS Output: 110

2025-08-14 15:19:28,437 INFO: [MODEL: llama3:8b] Output token usage: 2.69%
2025-08-14 15:19:28,437 INFO: [MODEL: llama3:8b] Output uses 110 tokens, remaining for response: 3636.
2025-08-14 15:19:28,990 INFO: JS Output: 269

2025-08-14 15:19:28,990 INFO: [MODEL: llama3:8b] Input token usage: 6.57%
2025-08-14 15:19:28,990 INFO: [MODEL: llama3:8b] Input uses 269 tokens, remaining for response: 3827.
2025-08-14 15:19:37,577 INFO: JS Output: 118

2025-08-14 15:19:37,577 INFO: [MODEL: llama3:8b] Output token usage: 2.88%
2025-08-14 15:19:37,593 INFO: [MODEL: llama3:8b] Output uses 118 tokens, remaining for response: 3709.
2025-08-14 15:19:38,107 INFO: JS Output: 356

2025-08-14 15:19:38,107 INFO: [MODEL: llama3:8b] Input token usage: 8.69%
2025-08-14 15:19:38,107 INFO: [MODEL: llama3:8b] Input uses 356 tokens, remaining for response: 3740.
2025-08-14 15:19:49,460 INFO: JS Output: 177

2025-08-14 15:19:49,460 INFO: [MODEL: llama3:8b] Output token usage: 4.32%
2025-08-14 15:19:49,460 INFO: [MODEL: llama3:8b] Output uses 177 tokens, remaining for response: 3563.
2025-08-14 15:19:49,974 INFO: JS Output: 269

2025-08-14 15:19:49,974 INFO: [MODEL: llama3:8b] Input token usage: 6.57%
2025-08-14 15:19:49,974 INFO: [MODEL: llama3:8b] Input uses 269 tokens, remaining for response: 3827.
2025-08-14 15:19:58,318 INFO: JS Output: 114

2025-08-14 15:19:58,318 INFO: [MODEL: llama3:8b] Output token usage: 2.78%
2025-08-14 15:19:58,318 INFO: [MODEL: llama3:8b] Output uses 114 tokens, remaining for response: 3713.
2025-08-14 15:19:58,822 INFO: JS Output: 187

2025-08-14 15:19:58,822 INFO: [MODEL: llama3:8b] Input token usage: 4.57%
2025-08-14 15:19:58,822 INFO: [MODEL: llama3:8b] Input uses 187 tokens, remaining for response: 3909.
2025-08-14 15:20:04,269 INFO: JS Output: 56

2025-08-14 15:20:04,269 INFO: [MODEL: llama3:8b] Output token usage: 1.37%
2025-08-14 15:20:04,269 INFO: [MODEL: llama3:8b] Output uses 56 tokens, remaining for response: 3853.
2025-08-14 15:20:04,792 INFO: JS Output: 292

2025-08-14 15:20:04,792 INFO: [MODEL: llama3:8b] Input token usage: 7.13%
2025-08-14 15:20:04,792 INFO: [MODEL: llama3:8b] Input uses 292 tokens, remaining for response: 3804.
2025-08-14 15:20:14,971 INFO: JS Output: 151

2025-08-14 15:20:14,971 INFO: [MODEL: llama3:8b] Output token usage: 3.69%
2025-08-14 15:20:14,971 INFO: [MODEL: llama3:8b] Output uses 151 tokens, remaining for response: 3653.
2025-08-14 15:20:15,507 INFO: JS Output: 184

2025-08-14 15:20:15,507 INFO: [MODEL: llama3:8b] Input token usage: 4.49%
2025-08-14 15:20:15,507 INFO: [MODEL: llama3:8b] Input uses 184 tokens, remaining for response: 3912.
2025-08-14 15:20:21,796 INFO: JS Output: 75

2025-08-14 15:20:21,796 INFO: [MODEL: llama3:8b] Output token usage: 1.83%
2025-08-14 15:20:21,796 INFO: [MODEL: llama3:8b] Output uses 75 tokens, remaining for response: 3837.
2025-08-14 15:20:22,289 INFO: JS Output: 72

2025-08-14 15:20:22,289 INFO: [MODEL: llama3:8b] Input token usage: 1.76%
2025-08-14 15:20:22,289 INFO: [MODEL: llama3:8b] Input uses 72 tokens, remaining for response: 4024.
2025-08-14 15:20:26,713 INFO: JS Output: 39

2025-08-14 15:20:26,718 INFO: [MODEL: llama3:8b] Output token usage: 0.95%
2025-08-14 15:20:26,718 INFO: [MODEL: llama3:8b] Output uses 39 tokens, remaining for response: 3985.
2025-08-14 15:20:27,214 INFO: JS Output: 819

2025-08-14 15:20:27,214 INFO: [MODEL: llama3:8b] Input token usage: 20.00%
2025-08-14 15:20:27,214 INFO: [MODEL: llama3:8b] Input uses 819 tokens, remaining for response: 3277.
2025-08-14 15:20:46,079 INFO: JS Output: 303

2025-08-14 15:20:46,079 INFO: [MODEL: llama3:8b] Output token usage: 7.40%
2025-08-14 15:20:46,079 INFO: [MODEL: llama3:8b] Output uses 303 tokens, remaining for response: 2974.
2025-08-14 15:20:46,594 INFO: JS Output: 1044

2025-08-14 15:20:46,594 INFO: [MODEL: llama3:8b] Input token usage: 25.49%
2025-08-14 15:20:46,594 INFO: [MODEL: llama3:8b] Input uses 1044 tokens, remaining for response: 3052.
2025-08-14 15:21:02,422 INFO: JS Output: 233

2025-08-14 15:21:02,424 INFO: [MODEL: llama3:8b] Output token usage: 5.69%
2025-08-14 15:21:02,424 INFO: [MODEL: llama3:8b] Output uses 233 tokens, remaining for response: 2819.

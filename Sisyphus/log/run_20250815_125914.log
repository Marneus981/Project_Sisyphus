2025-08-15 12:59:14,228 INFO: Waiting for Ollama to be ready...
2025-08-15 12:59:16,264 INFO: Ollama is running.
2025-08-15 12:59:16,349 INFO: Refreshing options...
2025-08-15 12:59:18,427 INFO: Options refreshed:
2025-08-15 12:59:18,427 INFO: Models: ['deepseek-r1:8b', 'llama3:8b']
2025-08-15 12:59:18,427 INFO: Systems: ['system1.txt', 'system_consistency.txt', 'system_consistency_cl.txt', 'system_cover_letter.txt']
2025-08-15 12:59:18,427 INFO: CVs: ['cv1.txt']
2025-08-15 12:59:18,427 INFO: CV Templates: ['cv_template.docx', 'cv_template2.docx', 'cv_template21.docx', 'cv_template21_simplest.docx']
2025-08-15 12:59:18,427 INFO: CL Templates: ['cl_template.docx']
2025-08-15 12:59:18,427 INFO: Previously Saved CV Outputs: ['cltrials.txt', 'consistency_tests0.txt', 'out_cv_20250724_213613.txt', 'out_cv_20250725_000423.txt', 'out_cv_20250725_001236.txt', 'out_cv_20250725_003414.txt', 'out_cv_20250725_004330.txt', 'out_cv_20250725_005646.txt', 'out_cv_20250730_011841.txt', 'out_cv_20250730_020338.txt', 'stableish0.txt']
2025-08-15 12:59:18,427 INFO: Previously Saved CL Outputs: ['cltest0.txt', 'out_cl_20250722_234433.txt', 'out_cl_20250723_230452.txt']
2025-08-15 13:00:07,216 INFO: CV loaded from C:\CodeProjects\Sisyphus\Sisyphus\saved_outputs\consistency_tests0.txt
2025-08-15 13:00:14,142 INFO: Summary of job description is empty. Generating summary...
2025-08-15 13:00:14,142 INFO: Job description is empty. Please enter a job description.
2025-08-15 13:00:19,333 INFO: Summary of job description is empty. Generating summary...
2025-08-15 13:00:20,139 INFO: JS Output: 97

2025-08-15 13:00:20,139 INFO: [MODEL: llama3:8b] Input token usage: 2.37%
2025-08-15 13:00:20,139 INFO: [MODEL: llama3:8b] Input uses 97 tokens, remaining for response: 3999.
2025-08-15 13:01:11,848 INFO: JS Output: 257

2025-08-15 13:01:11,848 INFO: [MODEL: llama3:8b] Output token usage: 6.27%
2025-08-15 13:01:11,848 INFO: [MODEL: llama3:8b] Output uses 257 tokens, remaining for response: 3742.
2025-08-15 13:01:11,852 INFO: slide_summary: candidate_name: Jane Doe
2025-08-15 13:01:11,852 INFO: slide_summary: candidate_title: Senior Software Engineer
2025-08-15 13:01:11,852 INFO: slide_summary: general_txts: 4
2025-08-15 13:01:11,852 INFO: slide_summary: special_txts: 6
2025-08-15 13:01:12,292 INFO: JS Output: 241

2025-08-15 13:01:12,292 INFO: [MODEL: llama3:8b] Input token usage: 5.88%
2025-08-15 13:01:12,292 INFO: [MODEL: llama3:8b] Input uses 241 tokens, remaining for response: 3855.
2025-08-15 13:01:44,544 INFO: JS Output: 139

2025-08-15 13:01:44,544 INFO: [MODEL: llama3:8b] Output token usage: 3.39%
2025-08-15 13:01:44,544 INFO: [MODEL: llama3:8b] Output uses 139 tokens, remaining for response: 3716.
2025-08-15 13:01:44,994 INFO: JS Output: 191

2025-08-15 13:01:44,994 INFO: [MODEL: llama3:8b] Input token usage: 4.66%
2025-08-15 13:01:44,994 INFO: [MODEL: llama3:8b] Input uses 191 tokens, remaining for response: 3905.
2025-08-15 13:02:31,031 INFO: JS Output: 134

2025-08-15 13:02:31,033 INFO: [MODEL: llama3:8b] Output token usage: 3.27%
2025-08-15 13:02:31,033 INFO: [MODEL: llama3:8b] Output uses 134 tokens, remaining for response: 3771.
2025-08-15 13:02:31,653 INFO: JS Output: 394

2025-08-15 13:02:31,659 INFO: [MODEL: llama3:8b] Input token usage: 9.62%
2025-08-15 13:02:31,659 INFO: [MODEL: llama3:8b] Input uses 394 tokens, remaining for response: 3702.
2025-08-15 13:02:45,355 INFO: JS Output: 228

2025-08-15 13:02:45,355 INFO: [MODEL: llama3:8b] Output token usage: 5.57%
2025-08-15 13:02:45,355 INFO: [MODEL: llama3:8b] Output uses 228 tokens, remaining for response: 3474.
2025-08-15 13:02:45,815 INFO: JS Output: 191

2025-08-15 13:02:45,815 INFO: [MODEL: llama3:8b] Input token usage: 4.66%
2025-08-15 13:02:45,815 INFO: [MODEL: llama3:8b] Input uses 191 tokens, remaining for response: 3905.
2025-08-15 13:02:53,344 INFO: JS Output: 100

2025-08-15 13:02:53,344 INFO: [MODEL: llama3:8b] Output token usage: 2.44%
2025-08-15 13:02:53,344 INFO: [MODEL: llama3:8b] Output uses 100 tokens, remaining for response: 3805.
2025-08-15 13:02:53,851 INFO: JS Output: 194

2025-08-15 13:02:53,851 INFO: [MODEL: llama3:8b] Input token usage: 4.74%
2025-08-15 13:02:53,851 INFO: [MODEL: llama3:8b] Input uses 194 tokens, remaining for response: 3902.
2025-08-15 13:03:02,762 INFO: JS Output: 135

2025-08-15 13:03:02,762 INFO: [MODEL: llama3:8b] Output token usage: 3.30%
2025-08-15 13:03:02,762 INFO: [MODEL: llama3:8b] Output uses 135 tokens, remaining for response: 3767.
2025-08-15 13:03:03,216 INFO: JS Output: 362

2025-08-15 13:03:03,216 INFO: [MODEL: llama3:8b] Input token usage: 8.84%
2025-08-15 13:03:03,216 INFO: [MODEL: llama3:8b] Input uses 362 tokens, remaining for response: 3734.
2025-08-15 13:03:16,651 INFO: JS Output: 225

2025-08-15 13:03:16,651 INFO: [MODEL: llama3:8b] Output token usage: 5.49%
2025-08-15 13:03:16,651 INFO: [MODEL: llama3:8b] Output uses 225 tokens, remaining for response: 3509.
2025-08-15 13:03:17,158 INFO: JS Output: 194

2025-08-15 13:03:17,158 INFO: [MODEL: llama3:8b] Input token usage: 4.74%
2025-08-15 13:03:17,158 INFO: [MODEL: llama3:8b] Input uses 194 tokens, remaining for response: 3902.
2025-08-15 13:03:25,690 INFO: JS Output: 119

2025-08-15 13:03:25,690 INFO: [MODEL: llama3:8b] Output token usage: 2.91%
2025-08-15 13:03:25,690 INFO: [MODEL: llama3:8b] Output uses 119 tokens, remaining for response: 3783.
2025-08-15 13:03:26,153 INFO: JS Output: 350

2025-08-15 13:03:26,153 INFO: [MODEL: llama3:8b] Input token usage: 8.54%
2025-08-15 13:03:26,153 INFO: [MODEL: llama3:8b] Input uses 350 tokens, remaining for response: 3746.
2025-08-15 13:03:35,879 INFO: JS Output: 152

2025-08-15 13:03:35,879 INFO: [MODEL: llama3:8b] Output token usage: 3.71%
2025-08-15 13:03:35,879 INFO: [MODEL: llama3:8b] Output uses 152 tokens, remaining for response: 3594.
2025-08-15 13:03:36,319 INFO: JS Output: 402

2025-08-15 13:03:36,319 INFO: [MODEL: llama3:8b] Input token usage: 9.81%
2025-08-15 13:03:36,319 INFO: [MODEL: llama3:8b] Input uses 402 tokens, remaining for response: 3694.
2025-08-15 13:03:50,621 INFO: JS Output: 250

2025-08-15 13:03:50,621 INFO: [MODEL: llama3:8b] Output token usage: 6.10%
2025-08-15 13:03:50,621 INFO: [MODEL: llama3:8b] Output uses 250 tokens, remaining for response: 3444.
2025-08-15 13:03:51,095 INFO: JS Output: 350

2025-08-15 13:03:51,095 INFO: [MODEL: llama3:8b] Input token usage: 8.54%
2025-08-15 13:03:51,095 INFO: [MODEL: llama3:8b] Input uses 350 tokens, remaining for response: 3746.
2025-08-15 13:04:00,513 INFO: JS Output: 144

2025-08-15 13:04:00,513 INFO: [MODEL: llama3:8b] Output token usage: 3.52%
2025-08-15 13:04:00,513 INFO: [MODEL: llama3:8b] Output uses 144 tokens, remaining for response: 3602.
2025-08-15 13:04:00,991 INFO: JS Output: 269

2025-08-15 13:04:00,991 INFO: [MODEL: llama3:8b] Input token usage: 6.57%
2025-08-15 13:04:00,991 INFO: [MODEL: llama3:8b] Input uses 269 tokens, remaining for response: 3827.
2025-08-15 13:04:10,108 INFO: JS Output: 138

2025-08-15 13:04:10,108 INFO: [MODEL: llama3:8b] Output token usage: 3.37%
2025-08-15 13:04:10,108 INFO: [MODEL: llama3:8b] Output uses 138 tokens, remaining for response: 3689.
2025-08-15 13:04:10,619 INFO: JS Output: 410

2025-08-15 13:04:10,619 INFO: [MODEL: llama3:8b] Input token usage: 10.01%
2025-08-15 13:04:10,619 INFO: [MODEL: llama3:8b] Input uses 410 tokens, remaining for response: 3686.
2025-08-15 13:04:27,400 INFO: JS Output: 299

2025-08-15 13:04:27,400 INFO: [MODEL: llama3:8b] Output token usage: 7.30%
2025-08-15 13:04:27,400 INFO: [MODEL: llama3:8b] Output uses 299 tokens, remaining for response: 3387.
2025-08-15 13:04:27,895 INFO: JS Output: 269

2025-08-15 13:04:27,895 INFO: [MODEL: llama3:8b] Input token usage: 6.57%
2025-08-15 13:04:27,895 INFO: [MODEL: llama3:8b] Input uses 269 tokens, remaining for response: 3827.
2025-08-15 13:04:35,300 INFO: JS Output: 100

2025-08-15 13:04:35,300 INFO: [MODEL: llama3:8b] Output token usage: 2.44%
2025-08-15 13:04:35,300 INFO: [MODEL: llama3:8b] Output uses 100 tokens, remaining for response: 3727.
2025-08-15 13:04:35,772 INFO: JS Output: 187

2025-08-15 13:04:35,772 INFO: [MODEL: llama3:8b] Input token usage: 4.57%
2025-08-15 13:04:35,772 INFO: [MODEL: llama3:8b] Input uses 187 tokens, remaining for response: 3909.
2025-08-15 13:04:41,702 INFO: JS Output: 70

2025-08-15 13:04:41,702 INFO: [MODEL: llama3:8b] Output token usage: 1.71%
2025-08-15 13:04:41,702 INFO: [MODEL: llama3:8b] Output uses 70 tokens, remaining for response: 3839.
2025-08-15 13:04:42,184 INFO: JS Output: 292

2025-08-15 13:04:42,184 INFO: [MODEL: llama3:8b] Input token usage: 7.13%
2025-08-15 13:04:42,184 INFO: [MODEL: llama3:8b] Input uses 292 tokens, remaining for response: 3804.
2025-08-15 13:04:52,577 INFO: JS Output: 163

2025-08-15 13:04:52,577 INFO: [MODEL: llama3:8b] Output token usage: 3.98%
2025-08-15 13:04:52,577 INFO: [MODEL: llama3:8b] Output uses 163 tokens, remaining for response: 3641.
2025-08-15 13:04:53,063 INFO: JS Output: 184

2025-08-15 13:04:53,063 INFO: [MODEL: llama3:8b] Input token usage: 4.49%
2025-08-15 13:04:53,063 INFO: [MODEL: llama3:8b] Input uses 184 tokens, remaining for response: 3912.
2025-08-15 13:04:59,067 INFO: JS Output: 71

2025-08-15 13:04:59,067 INFO: [MODEL: llama3:8b] Output token usage: 1.73%
2025-08-15 13:04:59,067 INFO: [MODEL: llama3:8b] Output uses 71 tokens, remaining for response: 3841.
2025-08-15 13:04:59,557 INFO: JS Output: 128

2025-08-15 13:04:59,557 INFO: [MODEL: llama3:8b] Input token usage: 3.12%
2025-08-15 13:04:59,557 INFO: [MODEL: llama3:8b] Input uses 128 tokens, remaining for response: 3968.
2025-08-15 13:05:05,251 INFO: JS Output: 66

2025-08-15 13:05:05,251 INFO: [MODEL: llama3:8b] Output token usage: 1.61%
2025-08-15 13:05:05,251 INFO: [MODEL: llama3:8b] Output uses 66 tokens, remaining for response: 3902.
2025-08-15 13:05:05,746 INFO: JS Output: 863

2025-08-15 13:05:05,746 INFO: [MODEL: llama3:8b] Input token usage: 21.07%
2025-08-15 13:05:05,746 INFO: [MODEL: llama3:8b] Input uses 863 tokens, remaining for response: 3233.
2025-08-15 13:05:28,158 INFO: JS Output: 394

2025-08-15 13:05:28,158 INFO: [MODEL: llama3:8b] Output token usage: 9.62%
2025-08-15 13:05:28,158 INFO: [MODEL: llama3:8b] Output uses 394 tokens, remaining for response: 2839.
